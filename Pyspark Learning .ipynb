{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ed521dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df944461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c87b073a",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e1a761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "877b09c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dave</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bob</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phil</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  age\n",
       "0  dave   31\n",
       "1   bob   30\n",
       "2  phil   29"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "pd.read_csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a096dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we start loading data with spark we need to start a SPARK SESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bdc35c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1bb3c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b3425fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://David-PC:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1da7b449990>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "961bb3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a9ba387c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f2af8cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "| _c0|_c1|\n",
      "+----+---+\n",
      "|name|age|\n",
      "|dave| 31|\n",
      "| bob| 30|\n",
      "|phil| 29|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9dfe847e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|dave| 31|\n",
      "| bob| 30|\n",
      "|phil| 29|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.option('header', 'true').csv('test1.csv').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f67205d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option('header', 'true').csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3d3468d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "39419b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='dave', age='31'),\n",
       " Row(name='bob', age='30'),\n",
       " Row(name='phil', age='29')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "34a8107b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c78d70f",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aa0cb641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e681a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fbec30fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://David-PC:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1da7b449990>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "595c6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when we are running from my memory on my PC - this is shown as 'local' - ie one node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ab3f54db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, age: string, experience : string]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read the data set\n",
    "\n",
    "spark.read.option('header', 'true').csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ec7bb64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----------+\n",
      "|name|age|experience |\n",
      "+----+---+-----------+\n",
      "|dave| 31|         10|\n",
      "| bob| 30|          8|\n",
      "|phil| 29|          4|\n",
      "+----+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.option('header', 'true').csv('test1.csv').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8b6b6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option('header', 'true').csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dda3b0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- experience : string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### check the schema\n",
    "\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "760c5dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default they have been as strings\n",
    "\n",
    "# to change this we need to input the variable within ''.csv(inferSchema = True)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a4250371",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option('header', 'true').csv('test1.csv',inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "243b1b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- experience : integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f683082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way of reading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8d97ab3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----------+\n",
      "|name|age|experience |\n",
      "+----+---+-----------+\n",
      "|dave| 31|         10|\n",
      "| bob| 30|          8|\n",
      "|phil| 29|          4|\n",
      "+----+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('test1.csv', header = True, inferSchema = True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f3799faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5c20ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ie what is a dataframe? - is it one kind of data structure, ie columns and rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a5ccf944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fdc1e603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'age', 'experience ']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2432cfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='dave', age=31, experience =10),\n",
       " Row(name='bob', age=30, experience =8),\n",
       " Row(name='phil', age=29, experience =4)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f9241575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----------+\n",
      "|name|age|experience |\n",
      "+----+---+-----------+\n",
      "|dave| 31|         10|\n",
      "| bob| 30|          8|\n",
      "|phil| 29|          4|\n",
      "+----+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2b91feb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.select('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "85edc611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|name|\n",
      "+----+\n",
      "|dave|\n",
      "| bob|\n",
      "|phil|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select('name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3a7a051b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark.select('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a1c6b9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, age: int]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.select('name', 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b2c8233f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|dave| 31|\n",
      "| bob| 30|\n",
      "|phil| 29|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['name', 'age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "60549b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to check data types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7110861c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'), ('age', 'int'), ('experience ', 'int')]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "694a28af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+-----------------+\n",
      "|summary|name| age|      experience |\n",
      "+-------+----+----+-----------------+\n",
      "|  count|   3|   3|                3|\n",
      "|   mean|NULL|30.0|7.333333333333333|\n",
      "| stddev|NULL| 1.0|3.055050463303893|\n",
      "|    min| bob|  29|                4|\n",
      "|    max|phil|  31|               10|\n",
      "+-------+----+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dc4c82a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "66870e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, age: int, experience : int, experience after 2 years: int]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.withColumn('experience after 2 years', df_pyspark['experience ']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "32cc12de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----------+------------------------+\n",
      "|name|age|experience |experience after 2 years|\n",
      "+----+---+-----------+------------------------+\n",
      "|dave| 31|         10|                      12|\n",
      "| bob| 30|          8|                      10|\n",
      "|phil| 29|          4|                       6|\n",
      "+----+---+-----------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumn('experience after 2 years', df_pyspark['experience ']+2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4daba6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.withColumn('experience after 2 years', df_pyspark['experience ']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "489fb474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----------+------------------------+\n",
      "|name|age|experience |experience after 2 years|\n",
      "+----+---+-----------+------------------------+\n",
      "|dave| 31|         10|                      12|\n",
      "| bob| 30|          8|                      10|\n",
      "|phil| 29|          4|                       6|\n",
      "+----+---+-----------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a084c6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7e192fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----------+\n",
      "|name|age|experience |\n",
      "+----+---+-----------+\n",
      "|dave| 31|         10|\n",
      "| bob| 30|          8|\n",
      "|phil| 29|          4|\n",
      "+----+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.drop('experience after 2 years').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "52db2d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.drop('experience after 2 years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "df610411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----------+\n",
      "|name|age|experience |\n",
      "+----+---+-----------+\n",
      "|dave| 31|         10|\n",
      "| bob| 30|          8|\n",
      "|phil| 29|          4|\n",
      "+----+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "71e9974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0e02cec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+-----------+\n",
      "|new name|age|experience |\n",
      "+--------+---+-----------+\n",
      "|    dave| 31|         10|\n",
      "|     bob| 30|          8|\n",
      "|    phil| 29|          4|\n",
      "+--------+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumnRenamed('name', 'new name').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f60beb1",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7c18861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a4600df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----------+------+\n",
      "| name| age|experience |salary|\n",
      "+-----+----+-----------+------+\n",
      "| dave|  31|         10| 30000|\n",
      "|  bob|  30|          8| 25000|\n",
      "| phil|  29|          4| 20000|\n",
      "|gemma|  24|       NULL| 20000|\n",
      "|  rob|  51|       NULL| 15000|\n",
      "|  gab|  28|       NULL| 18000|\n",
      "| toby|NULL|       NULL| 40000|\n",
      "| NULL|  34|         10| 38000|\n",
      "| NULL|  36|       NULL|  NULL|\n",
      "+-----+----+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.csv('test1.csv', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6af92481",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('test1.csv', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8b60de42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----------+------+\n",
      "| name| age|experience |salary|\n",
      "+-----+----+-----------+------+\n",
      "| dave|  31|         10| 30000|\n",
      "|  bob|  30|          8| 25000|\n",
      "| phil|  29|          4| 20000|\n",
      "|gemma|  24|       NULL| 20000|\n",
      "|  rob|  51|       NULL| 15000|\n",
      "|  gab|  28|       NULL| 18000|\n",
      "| toby|NULL|       NULL| 40000|\n",
      "| NULL|  34|         10| 38000|\n",
      "| NULL|  36|       NULL|  NULL|\n",
      "+-----+----+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3bb8eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3d4579d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+------+\n",
      "| age|experience |salary|\n",
      "+----+-----------+------+\n",
      "|  31|         10| 30000|\n",
      "|  30|          8| 25000|\n",
      "|  29|          4| 20000|\n",
      "|  24|       NULL| 20000|\n",
      "|  51|       NULL| 15000|\n",
      "|  28|       NULL| 18000|\n",
      "|NULL|       NULL| 40000|\n",
      "|  34|         10| 38000|\n",
      "|  36|       NULL|  NULL|\n",
      "+----+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.drop('name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "796b38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows depending on nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3cb93a75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----------+------+\n",
      "|name|age|experience |salary|\n",
      "+----+---+-----------+------+\n",
      "|dave| 31|         10| 30000|\n",
      "| bob| 30|          8| 25000|\n",
      "|phil| 29|          4| 20000|\n",
      "+----+---+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# where there is a null, the whole row is dropped \n",
    "\n",
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db7beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6a80f14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----------+------+\n",
      "| name| age|experience |salary|\n",
      "+-----+----+-----------+------+\n",
      "| dave|  31|         10| 30000|\n",
      "|  bob|  30|          8| 25000|\n",
      "| phil|  29|          4| 20000|\n",
      "|gemma|  24|       NULL| 20000|\n",
      "|  rob|  51|       NULL| 15000|\n",
      "|  gab|  28|       NULL| 18000|\n",
      "| toby|NULL|       NULL| 40000|\n",
      "| NULL|  34|         10| 38000|\n",
      "| NULL|  36|       NULL|  NULL|\n",
      "+-----+----+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if all rows have nulls\n",
    "\n",
    "df.na.drop(how = 'all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f59f821f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----------+------+\n",
      "|name|age|experience |salary|\n",
      "+----+---+-----------+------+\n",
      "|dave| 31|         10| 30000|\n",
      "| bob| 30|          8| 25000|\n",
      "|phil| 29|          4| 20000|\n",
      "+----+---+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if any rows have nulls they will be dropped\n",
    "\n",
    "df.na.drop(how = 'any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "26efa97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "55a3243e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----------+------+\n",
      "| name| age|experience |salary|\n",
      "+-----+----+-----------+------+\n",
      "| dave|  31|         10| 30000|\n",
      "|  bob|  30|          8| 25000|\n",
      "| phil|  29|          4| 20000|\n",
      "|gemma|  24|       NULL| 20000|\n",
      "|  rob|  51|       NULL| 15000|\n",
      "|  gab|  28|       NULL| 18000|\n",
      "| toby|NULL|       NULL| 40000|\n",
      "| NULL|  34|         10| 38000|\n",
      "+-----+----+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how = 'all', thresh = 2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baeff56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
